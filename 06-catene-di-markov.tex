\input{preambolo_comune}

% --- Titolo ---
\title{Catene di Markov}
\author{Basato sulle prove d'esame}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\label{cap:markov}
Una catena di Markov è un modello matematico per descrivere sistemi che evolvono nel tempo tra un insieme discreto di stati, dove la probabilità di transizione al prossimo stato dipende solo dallo stato attuale e non dalla sequenza di eventi che lo hanno preceduto (proprietà di Markov).

\section{Definizioni e Notazioni}
\begin{itemize}
    \item \textbf{Spazio degli Stati $S$}: L'insieme (finito o numerabile) di tutti i possibili stati del sistema. Es: $S=\{0, 1, 2\}$ o $S=\{A, B, C, D\}$.
    \item \textbf{Tempo Discreto}: Osserviamo il sistema a istanti $n=0, 1, 2, \dots$.
    \item \textbf{$X_n$}: La variabile aleatoria che rappresenta lo stato del sistema al tempo $n$.
    \item \textbf{Proprietà di Markov}:
    \[ \Prob(X_{n+1}=j | X_n=i, X_{n-1}=i_{n-1}, \dots, X_0=i_0) = \Prob(X_{n+1}=j | X_n=i) \]
    \item \textbf{Probabilità di Transizione (omogenee nel tempo)}: $p_{ij} = \Prob(X_{n+1}=j | X_n=i)$. Non dipendono da $n$.
    \item \textbf{Matrice di Transizione $P$}: Una matrice quadrata le cui entrate sono $p_{ij}$.
    \[ P = [p_{ij}]_{i,j \in S} \]
    Proprietà di $P$:
    \begin{itemize}
        \item $p_{ij} \ge 0$ per ogni $i,j$.
        \item $\sum_{j \in S} p_{ij} = 1$ per ogni riga $i$ (da ogni stato si deve transire da qualche parte).
    \end{itemize}
    \item \textbf{Grafo della Catena}: Un grafo orientato dove i nodi sono gli stati e un arco da $i$ a $j$ esiste se $p_{ij}>0$, etichettato con $p_{ij}$.
    \item \textbf{Probabilità di Transizione a n-passi $p_{ij}^{(n)}$}: $p_{ij}^{(n)} = \Prob(X_n=j | X_0=i)$.
    La matrice $P^{(n)}$ delle probabilità di transizione a $n$-passi è $P^{(n)} = P \cdot P \cdot \dots \cdot P = P^n$ (prodotto di matrici).
\end{itemize}

\begin{example}[Esercizio 4, 22/05/2024 - Genotipi Conigli]
\textit{Problema (parte a):} Stati: 0 (gg), 1 (gG), 2 (GG). $X_{n-1}$ è il genotipo di un genitore, l'altro è sempre un ibrido (gG, stato 1). $X_n$ è il genotipo della prole. Determinare la matrice di transizione.
\textit{Soluzione Passo Passo (calcolo di una riga della matrice):}
Consideriamo $p_{0j} = \Prob(X_n=j | X_{n-1}=0)$. Cioè, genitore 1 è 'gg', genitore 2 è 'gG'.
Ogni genitore dà un allele (g o G) con probabilità 1/2 (se ibrido) o 1 (se omozigote).
\begin{itemize}
    \item Genitore 1 (gg) dà sempre 'g'.
    \item Genitore 2 (gG) dà 'g' con prob 1/2, 'G' con prob 1/2.
\end{itemize}
Prole:
\begin{itemize}
    \item $X_n=0$ (gg): si ottiene se Genitore 1 dà 'g' E Genitore 2 dà 'g'. Prob = $1 \cdot (1/2) = 1/2$. Quindi $p_{00}=1/2$.
    \item $X_n=1$ (gG): si ottiene se Genitore 1 dà 'g' E Genitore 2 dà 'G'. Prob = $1 \cdot (1/2) = 1/2$. Quindi $p_{01}=1/2$.
    \item $X_n=2$ (GG): impossibile. Prob = 0. Quindi $p_{02}=0$.
\end{itemize}
Prima riga di $P$: $[1/2, 1/2, 0]$.
Analogamente si calcolano le altre righe. La soluzione fornisce:
\[ P = \begin{pmatrix} 1/2 & 1/2 & 0 \\ 1/4 & 1/2 & 1/4 \\ 0 & 1/2 & 1/2 \end{pmatrix} \]
Il grafo si disegna con 3 nodi (0,1,2) e gli archi pesati con le $p_{ij}$ non nulle.
\end{example}

\section{Classificazione degli Stati}
\begin{itemize}
    \item Uno stato $j$ è \textbf{accessibile} da $i$ ($i \to j$) se $p_{ij}^{(n)} > 0$ per qualche $n \ge 0$.
    \item Due stati $i,j$ \textbf{comunicano} ($i \leftrightarrow j$) se $i \to j$ e $j \to i$. La comunicazione è una relazione di equivalenza e partiziona $S$ in \textbf{classi comunicanti}.
    \item Una catena è \textbf{irriducibile} se ha una sola classe comunicante (tutti gli stati comunicano tra loro).
    \item Uno stato $i$ è \textbf{ricorrente} se, partendo da $i$, la probabilità di ritornare in $i$ è 1. Altrimenti è \textbf{transiente}.
    \begin{itemize}
        \item In una classe comunicante finita, tutti gli stati sono o tutti ricorrenti o tutti transienti.
        \item Se una classe è chiusa (non si può uscire) e finita, allora è ricorrente.
    \end{itemize}
    \item Uno stato $i$ è \textbf{assorbente} se $p_{ii}=1$ (una volta entrati, non si esce più). Uno stato assorbente forma una classe comunicante ricorrente da solo.
    \item Il \textbf{periodo} $d(i)$ di uno stato $i$ è il MCD$\{n \ge 1 : p_{ii}^{(n)} > 0\}$. Se $d(i)=1$, lo stato è \textbf{aperiodico}.
    \begin{itemize}
        \item Tutti gli stati nella stessa classe comunicante hanno lo stesso periodo.
        \item Se una catena irriducibile ha almeno un $p_{ii}>0$ (cappio nel grafo), allora è aperiodica.
    \end{itemize}
\end{itemize}

\section{Distribuzione Stazionaria (Invariante)}
\begin{definition}[Distribuzione Stazionaria]
Un vettore riga di probabilità $\pi = (\pi_0, \pi_1, \dots)$ è una \textbf{distribuzione stazionaria} (o invariante) se soddisfa:
\[ \pi P = \pi \quad \text{e} \quad \sum_i \pi_i = 1 \]
Se la distribuzione iniziale degli stati è $\pi$, allora anche la distribuzione al tempo successivo sarà $\pi$. Rappresenta l'equilibrio a lungo termine della catena.
\end{definition}

\begin{theorem}[Teorema Ergodico]
Se una catena di Markov è \textbf{irriducibile} e \textbf{aperiodica} (e ha spazio degli stati finito), allora:
\begin{enumerate}
    \item Esiste un'unica distribuzione stazionaria $\pi$.
    \item Per ogni stato iniziale $i$ e ogni stato $j$, $\lim_{n \to \infty} p_{ij}^{(n)} = \pi_j$.
    (Le righe della matrice $P^n$ convergono tutte al vettore $\pi$).
\end{enumerate}
Se la catena è irriducibile ma periodica, il limite sopra non esiste, ma esiste ancora un'unica distribuzione stazionaria.
\end{theorem}

\begin{example}[Esercizio 4, Punto b, 22/05/2024 - Conigli]
Determinare la distribuzione invariante $\pi = (\pi_0, \pi_1, \pi_2)$ per $P = \begin{pmatrix} 1/2 & 1/2 & 0 \\ 1/4 & 1/2 & 1/4 \\ 0 & 1/2 & 1/2 \end{pmatrix}$.
\textit{Soluzione Passo Passo:}
\begin{enumerate}
    \item \textbf{Impostare il sistema $\pi P = \pi$:}
    \begin{align*}
        \pi_0 &= \frac{1}{2}\pi_0 + \frac{1}{4}\pi_1 + 0\pi_2 \\
        \pi_1 &= \frac{1}{2}\pi_0 + \frac{1}{2}\pi_1 + \frac{1}{2}\pi_2 \\
        \pi_2 &= 0\pi_0 + \frac{1}{4}\pi_1 + \frac{1}{2}\pi_2
    \end{align*}
    E la condizione di normalizzazione: $\pi_0 + \pi_1 + \pi_2 = 1$.
    \item \textbf{Semplificare le equazioni:}
    (1) $\frac{1}{2}\pi_0 = \frac{1}{4}\pi_1 \Rightarrow 2\pi_0 = \pi_1$.
    (3) $\frac{1}{2}\pi_2 = \frac{1}{4}\pi_1 \Rightarrow 2\pi_2 = \pi_1$.
    (Notare che la (2) diventa: $\frac{1}{2}\pi_1 = \frac{1}{2}\pi_0 + \frac{1}{2}\pi_2 \Rightarrow \pi_1 = \pi_0 + \pi_2$. Se sostituiamo $\pi_0=\pi_1/2$ e $\pi_2=\pi_1/2$, otteniamo $\pi_1 = \pi_1/2 + \pi_1/2 \Rightarrow \pi_1=\pi_1$, quindi la (2) è linearmente dipendente dalle altre due).
    \item \textbf{Usare la normalizzazione:}
    Da $2\pi_0 = \pi_1$ e $2\pi_2 = \pi_1$, abbiamo $\pi_0 = \pi_1/2$ e $\pi_2 = \pi_1/2$.
    Sostituiamo in $\pi_0 + \pi_1 + \pi_2 = 1$:
    $\frac{\pi_1}{2} + \pi_1 + \frac{\pi_1}{2} = 1 \Rightarrow 2\pi_1 = 1 \Rightarrow \pi_1 = 1/2$.
    \item \textbf{Trovare $\pi_0$ e $\pi_2$:}
    $\pi_0 = \pi_1/2 = (1/2)/2 = 1/4$.
    $\pi_2 = \pi_1/2 = (1/2)/2 = 1/4$.
    Quindi $\pi = (1/4, 1/2, 1/4)$. Questo corrisponde alla soluzione.
    \item \textbf{Cosa si può dire del genotipo alla centesima generazione?}
    La catena è irriducibile (tutti gli stati comunicano) e aperiodica (ad es. $p_{11}=1/2 > 0$, quindi $d(1)=1$). Per il teorema ergodico, la distribuzione degli stati dopo molti passi converge a $\pi$. Quindi, alla centesima generazione, la probabilità che il coniglio sia gg è $\approx \pi_0=1/4$, gG è $\approx \pi_1=1/2$, GG è $\approx \pi_2=1/4$.
\end{enumerate}
\end{example}

\section{Probabilità di Assorbimento}
Se una catena ha uno o più stati assorbenti, siamo spesso interessati alla probabilità che, partendo da uno stato transiente $i$, la catena venga assorbita in un particolare stato assorbente $j$.
Sia $h_i$ la probabilità di essere assorbiti in un certo stato (o insieme di stati) assorbente $S_A$, partendo dallo stato $i$.
Si imposta un sistema di equazioni:
\begin{itemize}
    \item $h_i = 1$ se $i \in S_A$ (se parto da uno stato assorbente, ci sono già).
    \item $h_i = 0$ se $i$ è uno stato assorbente che NON è in $S_A$ (se l'obiettivo è essere assorbiti in A, ma parto da un altro stato assorbente B, non potrò mai raggiungere A).
    \item Per gli stati transienti $i$: $h_i = \sum_{k \in S} p_{ik} h_k$. (Condizionando sul primo passo).
\end{itemize}
\begin{example}[Esercizio 4, Punto c, 17/07/2024 - Jack's game]
\textit{Problema:} Jack ha 2 euro, vuole arrivare a 8 euro (chiamata). Strategia 1: scommette 2 euro. P(vince)=0.4, P(perde)=0.6. Stati: 0, 2, 4, 6, 8 (euro). 0 e 8 sono assorbenti.
Qual è la probabilità di arrivare a 8 partendo da 2 (ovvero $h_2^8$)?
Matrice di transizione (solo stati rilevanti per calcolare $h_i^8$):
Stati: 0 (assorbente, non vince), 2 (transiente), 4 (transiente), 6 (transiente), 8 (assorbente, vince)
$P = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\ % da 0
p_{20} & 0 & p_{24} & 0 & 0 \\ % da 2 (perde va a 0, vince va a 4)
0 & p_{42} & 0 & p_{46} & 0 \\ % da 4
0 & 0 & p_{64} & 0 & p_{68} \\ % da 6
0 & 0 & 0 & 0 & 1    % da 8
\end{pmatrix}$
$p_{i, i-2} = 0.6$ (perde 2), $p_{i, i+2} = 0.4$ (vince 2).
Quindi $p_{20}=0.6, p_{24}=0.4$; $p_{42}=0.6, p_{46}=0.4$; $p_{64}=0.6, p_{68}=0.4$.
Sistema per $h_i = \Prob(\text{raggiungere 8 prima di 0, partendo da i})$:
\begin{itemize}
    \item $h_0 = 0$ (partendo da 0 non si raggiunge 8 come prima cosa).
    \item $h_8 = 1$ (partendo da 8 si è già raggiunto).
    \item $h_2 = p_{20}h_0 + p_{24}h_4 = 0.6(0) + 0.4h_4 = 0.4h_4$.
    \item $h_4 = p_{42}h_2 + p_{46}h_6 = 0.6h_2 + 0.4h_6$.
    \item $h_6 = p_{64}h_4 + p_{68}h_8 = 0.6h_4 + 0.4(1) = 0.6h_4 + 0.4$.
\end{itemize}
Sostituiamo:
$h_4 = 0.6(0.4h_4) + 0.4(0.6h_4 + 0.4)$
$h_4 = 0.24h_4 + 0.24h_4 + 0.16$
$h_4 = 0.48h_4 + 0.16$
$h_4(1 - 0.48) = 0.16 \Rightarrow 0.52h_4 = 0.16 \Rightarrow h_4 = 0.16/0.52 = 16/52 = 4/13$.
Allora $h_2 = 0.4 h_4 = (2/5)(4/13) = 8/65$.
$h_6 = 0.6(4/13) + 0.4 = (12/65) + (26/65) = 38/65$. (Errore nella soluzione data dell'esame, $h_6^8$ è $38/65 \approx 0.58$, non $4/25$).
La soluzione fornita nell'esame ha $h_2^8 = 8/65 \approx 0.1231$. Questo è il valore corretto per $h_2$.
La soluzione dice $h_4^8 = 4/13$, $h_6^8 = 8/25$ (questo sembra un errore, dovrebbe essere $h_6 = 0.6(4/13)+0.4 = (2.4/13)+0.4 = (12/65) + (26/65) = 38/65$).
Ma il calcolo di $h_2^8=8/65$ è corretto.

Per la strategia 2: Stati 0, 2, 4, 8. $P(\text{vince})=0.4, P(\text{perde})=0.6$. Scommette tutto.
\begin{itemize}
    \item Da 2: scommette 2. Vince $\to$ 4 (prob 0.4). Perde $\to$ 0 (prob 0.6).
    \item Da 4: scommette 4. Vince $\to$ 8 (prob 0.4). Perde $\to$ 0 (prob 0.6).
\end{itemize}
Sistema per $h_i = \Prob(\text{raggiungere 8 prima di 0, partendo da i})$:
\begin{itemize}
    \item $h_0 = 0$.
    \item $h_8 = 1$.
    \item $h_2 = p_{20}h_0 + p_{24}h_4 = 0.6(0) + 0.4h_4 = 0.4h_4$.
    \item $h_4 = p_{40}h_0 + p_{48}h_8 = 0.6(0) + 0.4(1) = 0.4$.
\end{itemize}
$h_4 = 0.4$.
$h_2 = 0.4 h_4 = 0.4(0.4) = 0.16 = 4/25$.
Confrontando $h_2$: Strategia 1 dà $8/65 \approx 0.123$. Strategia 2 dà $0.16$.
La strategia 2 è migliore, come indicato nella soluzione.
\end{example}


\end{document}
