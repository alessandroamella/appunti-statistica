\input{preambolo_comune}

% --- Titolo ---
\title{Fondamenti di Probabilità}
\author{Basato sulle prove d'esame}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\label{cap:fondamenti}
In questo capitolo introdurremo i concetti di base del calcolo delle probabilità, che sono il mattone fondamentale per tutto ciò che seguirà.

\section{Spazio Campionario (\texorpdfstring{$\Omega$}{Omega}) ed Eventi}

\begin{definition}[Esperimento Aleatorio]
Un \textbf{esperimento aleatorio} è un processo il cui esito non può essere previsto con certezza prima che venga eseguito, anche se tutte le possibili realizzazioni sono note.
\end{definition}

\begin{example}
Esempi di esperimenti aleatori sono:
\begin{itemize}
    \item Il lancio di una moneta (possibili esiti: Testa, Croce).
    \item Il lancio di un dado a sei facce (possibili esiti: 1, 2, 3, 4, 5, 6).
    \item L'estrazione di una carta da un mazzo.
    \item La scelta di uno studente da una classe per un'interrogazione.
\end{itemize}
\end{example}

\begin{definition}[Spazio Campionario \texorpdfstring{$\Omega$}{Omega}]
Lo \textbf{spazio campionario}, indicato con $\Omega$, è l'insieme di tutti i possibili esiti (o risultati elementari) di un esperimento aleatorio.
\end{definition}

\begin{example}
\begin{enumerate}
    \item Lancio di una moneta: $\Omega = \{T, C\}$ (dove T=Testa, C=Croce).
    \item Lancio di un dado: $\Omega = \{1, 2, 3, 4, 5, 6\}$.
    \item Lancio di due monete (o una moneta due volte): $\Omega = \{(T,T), (T,C), (C,T), (C,C)\}$. Nota che l'ordine può essere importante.
    \item \textbf{Esercizio 2, 08/09/2023 (Scelta gruppo):} Una classe di 10 studenti viene suddivisa in due sottogruppi di 5. Il primo va a Firenze, il secondo a Roma. Se definiamo un esito come la composizione del gruppo che va a Roma (o Firenze), $\Omega$ è l'insieme di tutte le possibili combinazioni di 5 studenti scelti da 10. Il numero di tali esiti è $\binom{10}{5}$.
\end{enumerate}
\end{example}

\begin{definition}[Evento]
Un \textbf{evento} $A$ è un qualsiasi sottoinsieme dello spazio campionario $\Omega$ (cioè $A \subseteq \Omega$). Un evento si dice \textbf{verificato} (o che si è realizzato) se l'esito dell'esperimento aleatorio è un elemento di $A$.
\end{definition}

\begin{example}
Consideriamo il lancio di un dado, $\Omega = \{1, 2, 3, 4, 5, 6\}$.
\begin{itemize}
    \item Evento $A = \text{"esce un numero pari"}$: $A = \{2, 4, 6\}$.
    \item Evento $B = \text{"esce un numero maggiore di 4"}$: $B = \{5, 6\}$.
    \item Evento $C = \text{"esce il numero 3"}$: $C = \{3\}$ (questo è un evento elementare).
    \item L'insieme vuoto $\emptyset$ è un evento, chiamato \textbf{evento impossibile} (non può mai verificarsi).
    \item Lo spazio campionario $\Omega$ è un evento, chiamato \textbf{evento certo} (si verifica sempre).
\end{itemize}
\end{example}

\subsection{Operazioni tra Eventi}
Essendo gli eventi degli insiemi, possiamo applicare le usuali operazioni insiemistiche:
\begin{itemize}
    \item \textbf{Unione ($A \cup B$):} L'evento "si verifica $A$ oppure si verifica $B$ (o entrambi)". Corrisponde al connettivo logico "OR".
    \item \textbf{Intersezione ($A \cap B$):} L'evento "si verificano sia $A$ che $B$". Corrisponde al connettivo logico "AND".
    \item \textbf{Complementare ($A^c$ o $\bar{A}$):} L'evento "non si verifica $A$".
\end{itemize}
Due eventi $A$ e $B$ si dicono \textbf{incompatibili} (o \textbf{disgiunti} o \textbf{mutuamente esclusivi}) se non possono verificarsi contemporaneamente, cioè se $A \cap B = \emptyset$.

\begin{example}
Sempre con il lancio del dado:
\begin{itemize}
    \item $A = \{2, 4, 6\}$, $B = \{5, 6\}$.
    \item $A \cup B = \{2, 4, 5, 6\}$ (esce un numero pari OPPURE un numero maggiore di 4).
    \item $A \cap B = \{6\}$ (esce un numero pari E maggiore di 4).
    \item $A^c = \{1, 3, 5\}$ (non esce un numero pari, cioè esce un numero dispari).
    \item Se $D = \{1, 3\}$, allora $A \cap D = \emptyset$, quindi $A$ e $D$ sono incompatibili.
\end{itemize}
\end{example}

\section{Definizione di Probabilità}
Vogliamo assegnare un numero a ciascun evento che ne misuri la "possibilità" di verificarsi.

\begin{definition}[Probabilità]
Dato uno spazio campionario $\Omega$, una \textbf{funzione di probabilità} $\Prob$ è una funzione che assegna a ogni evento $A \subseteq \Omega$ un numero reale $\Prob(A)$ tale che siano soddisfatti i seguenti assiomi (assiomi di Kolmogorov):
\begin{enumerate}
    \item $\Prob(A) \ge 0$ per ogni evento $A$ (non negatività).
    \item $\Prob(\Omega) = 1$ (normalizzazione: l'evento certo ha probabilità 1).
    \item Se $A_1, A_2, \dots, A_n, \dots$ è una successione di eventi a due a due incompatibili (cioè $A_i \cap A_j = \emptyset$ per $i \neq j$), allora
    \[ \Prob\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} \Prob(A_i) \quad (\sigma\text{-additività}) \]
    Se lo spazio campionario $\Omega$ è finito, la $\sigma$-additività si riduce alla \textbf{additività finita}: se $A$ e $B$ sono incompatibili ($A \cap B = \emptyset$), allora $\Prob(A \cup B) = \Prob(A) + \Prob(B)$.
\end{enumerate}
\end{definition}

Da questi assiomi derivano alcune proprietà importanti:
\begin{itemize}
    \item $\Prob(\emptyset) = 0$.
    \item Se $A \subseteq B$, allora $\Prob(A) \le \Prob(B)$.
    \item $0 \le \Prob(A) \le 1$ per ogni evento $A$.
    \item $\Prob(A^c) = 1 - \Prob(A)$.
\begin{remark}[Utilità dell'Evento Complementare]\label{remark:complementare}
La probabilità dell'evento complementare $A^c$ (cioè "l'evento A non si verifica") è data da $1 - \Prob(A)$. Questa relazione è estremamente utile in pratica. Spesso, calcolare direttamente la probabilità di un evento $A$ può essere complesso perché $A$ potrebbe verificarsi in molti modi diversi. In tali casi, potrebbe essere significativamente più semplice calcolare la probabilità che $A$ *non* si verifichi, cioè $\Prob(A^c)$, e poi ottenere $\Prob(A)$ per sottrazione.
Ad esempio, se l'evento $A$ è "almeno una testa in 3 lanci di moneta", l'evento complementare $A^c$ è "nessuna testa in 3 lanci" (cioè tutte croci, CCC). È più facile calcolare $\Prob(A^c)$ e poi $\Prob(A) = 1 - \Prob(A^c)$.
Questa strategia è usata nell'Esercizio 1, Punto 3, dove per calcolare la probabilità $P$ che "il gioco termina con lo scommettitore che non perde tutti i soldi", si calcola prima la probabilità $P^c$ che "lo scommettitore perda tutti i soldi".
\end{remark}
    \item $\Prob(A \cup B) = \Prob(A) + \Prob(B) - \Prob(A \cap B)$ (principio di inclusione-esclusione per due eventi).
\end{itemize}

\subsection{Spazi Equiprobabili e Calcolo Combinatorio}
In molti problemi, specialmente quelli che coinvolgono dadi, monete "bilanciate", o estrazioni "casuali", si assume che tutti gli esiti elementari in $\Omega$ abbiano la stessa probabilità di verificarsi. Questo è il caso di uno \textbf{spazio campionario equiprobabile} (o uniforme).

Se $\Omega$ è uno spazio campionario finito con $N = |\Omega|$ esiti elementari, e se ogni esito ha la stessa probabilità, allora la probabilità di un singolo esito $\omega_i$ è $\Prob(\{\omega_i\}) = 1/N$.
In questo caso, la probabilità di un evento $A$ è data da:
\[ \Prob(A) = \frac{\text{numero di esiti favorevoli ad } A}{\text{numero di esiti possibili}} = \frac{|A|}{|\Omega|} \]

Il \textbf{calcolo combinatorio} ci fornisce gli strumenti per contare efficacemente $|A|$ e $|\Omega|$. La chiave è capire quale strumento usare in base alle caratteristiche del problema:
\begin{itemize}
    \item Se l'ordine conta e possiamo riutilizzare gli elementi → Disposizioni con Ripetizione
    \item Se l'ordine conta e NON possiamo riutilizzare gli elementi → Disposizioni Semplici
    \item Se l'ordine NON conta e NON possiamo riutilizzare gli elementi → Combinazioni Semplici
    \item Se dobbiamo solo ordinare tutti gli elementi → Permutazioni Semplici
\end{itemize}

\subsubsection{Principio Fondamentale del Conteggio (Metodo delle Scelte Successive)}
\label{subsubsec:principio_moltiplicazione}

Molti problemi di conteggio, specialmente quelli che coinvolgono la determinazione del numero di esiti possibili ($|\Omega|$) o del numero di esiti favorevoli a un evento ($|A|$), possono essere risolti scomponendo il processo di selezione o costruzione in una sequenza di \textbf{scelte successive}.

\noindent Il \textbf{Principio di Moltiplicazione} (o Regola del Prodotto) afferma che se un'operazione può essere eseguita in $k$ passi (o scelte), e
\begin{itemize}
    \item il primo passo può essere eseguito in $n_1$ modi,
    \item per ciascuno di questi modi, il secondo passo può essere eseguito in $n_2$ modi,
    \item per ciascuna combinazione dei primi due passi, il terzo passo può essere eseguito in $n_3$ modi,
    \item e così via, fino al $k$-esimo passo che può essere eseguito in $n_k$ modi (dove il numero di modi per una scelta può dipendere dalle scelte precedenti, ma è fissato una volta che tali scelte sono note),
\end{itemize}
allora il numero totale di modi per eseguire l'intera operazione è il prodotto $N = n_1 \cdot n_2 \cdot n_3 \cdot \dots \cdot n_k$.

\begin{example}[Scelta di un pasto]
Un ristorante offre un menù fisso con 3 antipasti, 4 primi e 2 dolci. Quanti pasti completi diversi si possono comporre scegliendo un antipasto, un primo e un dolce?
\begin{itemize}
    \item Scelta 1 (Antipasto): $n_1 = 3$ modi.
    \item Scelta 2 (Primo): $n_2 = 4$ modi (per ogni antipasto scelto).
    \item Scelta 3 (Dolce): $n_3 = 2$ modi (per ogni coppia antipasto-primo scelta).
\end{itemize}
Numero totale di pasti possibili: $N = n_1 \cdot n_2 \cdot n_3 = 3 \cdot 4 \cdot 2 = 24$.

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[
        node distance=1.2cm, % Distanza verticale tra i livelli
        every node/.style={
            align=center,
            text=primarytext,
            draw=nodecolor,
            fill=nodecolor!60, % Riempimento leggermente più chiaro
            rounded corners,
            minimum width=2.5cm,
            font=\small
        },
        edge from parent/.style={draw=linkcolor, thick, -latex}, % Stile per le frecce
        dots_node/.style={draw=none, fill=none, text=linkcolor!70, font=\Large} % Stile per i nodi "..."
    ]

    % Nodo radice (Scelta iniziale)
    \node (root) {Scelta del Pasto};

    % Livello 1: Antipasti
    % Mostriamo il primo antipasto e un nodo "..." per gli altri
    \node (ant1) [below=of root, xshift=-1.5cm] {Antipasto 1\\(\textbf{3} opzioni totali)};
    \node (ant_dots) [dots_node, below=of root, xshift=1.5cm] {$\vdots$};
    \draw (root) -- (ant1);
    \draw (root) -- (ant_dots); % Connessione per i puntini verticali

    % Livello 2: Primi per Antipasto 1
    % Mostriamo il primo primo e un nodo "..." per gli altri
    \node (primo1_ant1) [below=of ant1, xshift=-1cm] {Primo 1\\(\textbf{4} opzioni totali)};
    \node (primo_dots) [dots_node, below=of ant1, xshift=1cm] {$\vdots$};
    \draw (ant1) -- (primo1_ant1);
    \draw (ant1) -- (primo_dots);

    % Livello 3: Dolci per Primo 1
    % Mostriamo entrambi i dolci, dato che sono solo due
    \node (dolce1_primo1) [below=of primo1_ant1, xshift=-1.5cm] {Dolce 1\\(\textbf{2} opzioni totali)};
    \node (dolce2_primo1) [below=of primo1_ant1, xshift=1.5cm] {Dolce 2\\(\textbf{2} opzioni totali)};
    \draw (primo1_ant1) -- (dolce1_primo1);
    \draw (primo1_ant1) -- (dolce2_primo1);

    % Nodo per il calcolo finale
    \node (total_calc) [below=0.7cm of dolce1_primo1.south, xshift=2cm, text=primarytext, font=\large, draw=none, fill=none] {Totale combinazioni: \textbf{$3 \times 4 \times 2 = 24$}};

    \end{tikzpicture}
    \caption{Rappresentazione ad albero del metodo delle scelte successive per la composizione di un pasto.}
    \label{fig:albero_scelte}
\end{figure}
\end{example}

\begin{example}[Formare un codice]
Quanti codici di 3 caratteri si possono formare se il primo carattere deve essere una lettera maiuscola (26 possibilità), il secondo una cifra (10 possibilità) e il terzo una lettera minuscola (26 possibilità), senza ripetizioni per le lettere se fossero entrambe maiuscole o minuscole e dallo stesso gruppo? In questo caso, le scelte sono indipendenti:
\begin{itemize}
    \item Scelta 1 (Primo carattere, lettera maiuscola): $n_1 = 26$ modi.
    \item Scelta 2 (Secondo carattere, cifra): $n_2 = 10$ modi.
    \item Scelta 3 (Terzo carattere, lettera minuscola): $n_3 = 26$ modi.
\end{itemize}
Numero totale di codici: $N = 26 \cdot 10 \cdot 26 = 6760$.
Se, invece, i tre caratteri fossero tre cifre diverse da 0 a 9, avremmo: $n_1=10, n_2=9, n_3=8$, per un totale di $10 \cdot 9 \cdot 8 = 720$ codici. Questo illustra come $n_i$ possa dipendere dalle scelte precedenti.
\end{example}

Le formule per disposizioni e permutazioni possono essere viste come applicazioni dirette di questo principio. Ad esempio, per le Disposizioni Semplici $D_{n,k}$ (scegliere e ordinare $k$ elementi da $n$ senza ripetizione):
\begin{itemize}
    \item Per il primo elemento, ci sono $n$ scelte.
    \item Per il secondo elemento (diverso dal primo), ci sono $n-1$ scelte.
    \item ...
    \item Per il $k$-esimo elemento, ci sono $n-k+1$ scelte.
\end{itemize}
Il numero totale di disposizioni è $n \cdot (n-1) \cdot \dots \cdot (n-k+1)$.

Nell'esempio degli studenti biondi a Roma (Esempio~\ref{ex:studenti-roma}, discusso più avanti), quando si calcola il numero di modi per formare un gruppo con 2 biondi e 3 non biondi, $|B_2| = \binom{4}{2} \cdot \binom{6}{3}$, si sta usando il principio di moltiplicazione: la scelta dei 2 studenti biondi (tra 4 disponibili) e la scelta dei 3 studenti non biondi (tra 6 disponibili) sono due "passi" o "scelte" la cui numerosità di modi si moltiplica per ottenere il totale.

\paragraph{Collegamento con la Probabilità}
Quando gli "oggetti" che contiamo sono sequenze di eventi casuali, il principio di moltiplicazione per il conteggio si traduce, nel dominio delle probabilità, nella \textbf{Regola della Catena} (vedi Corollario~\ref{cor:catena}) per il calcolo della probabilità di un'intersezione di eventi. Questo aspetto è trattato in dettaglio nella Sezione~\ref{sec:prob_cond} sulla probabilità condizionata. Ad esempio, la probabilità di una sequenza di estrazioni da un'urna (come nell'esempio dell'Urna di Polya) è calcolata moltiplicando le probabilità condizionate di ogni estrazione, data la storia delle estrazioni precedenti.

\subsubsection{Disposizioni con Ripetizione}
\textbf{Formula:} $DR_{n,k} = n^k$

\textbf{Quando usarla:}
\begin{itemize}
    \item Quando possiamo \textbf{riutilizzare} gli stessi elementi
    \item Quando l'\textbf{ordine} è importante
    \item Quando dobbiamo fare $k$ scelte tra $n$ possibilità
\end{itemize}

\textbf{Esempi:}
\begin{enumerate}
    \item \textbf{Password di lunghezza 4 con cifre 0-9:}
    \begin{itemize}
        \item $n=10$ (cifre disponibili)
        \item $k=4$ (lunghezza password)
        \item Posso riusare le cifre (es: "1111" è valida)
        \item L'ordine conta ("1234" $\neq$ "4321")
        \item $DR_{10,4} = 10^4 = 10000$ possibili password
    \end{itemize}

    \item \textbf{Sequenze di 3 lanci di una moneta:}
    \begin{itemize}
        \item $n=2$ (T/C)
        \item $k=3$ (lanci)
        \item $DR_{2,3} = 2^3 = 8$ possibili sequenze: TTT, TTC, TCT, TCC, CTT, CTC, CCT, CCC
    \end{itemize}

    \item \textbf{Esempio:} 5 palline in 3 urne
    \begin{itemize}
        \item $n=3$ (urne A, B, C)
        \item $k=5$ (palline)
        \item Per ogni pallina posso scegliere una qualsiasi urna
        \item $DR_{3,5} = 3^5 = 243$ possibili distribuzioni
    \end{itemize}
\end{enumerate}

\subsubsection{Permutazioni Semplici}
\textbf{Formula:} $P_n = n!$

\textbf{Quando usarla:}
\begin{itemize}
    \item Quando dobbiamo ordinare \textbf{tutti} gli elementi di un insieme
    \item Quando ogni elemento deve essere usato \textbf{esattamente una volta}
    \item Quando l'\textbf{ordine} è importante
\end{itemize}

\textbf{Esempi:}
\begin{enumerate}
    \item \textbf{Anagrammi della parola "CASA":}
    \begin{itemize}
        \item $n=4$ (lettere)
        \item $P_4 = 4! = 24$ anagrammi
        \item CASA, ACSA, ASCA, SACA, CSAA, CASS, ...
    \end{itemize}

    \item \textbf{Ordinare 5 persone in fila:}
    \begin{itemize}
        \item $n=5$ (persone)
        \item $P_5 = 5! = 120$ possibili file
    \end{itemize}

    \item \textbf{Percorsi tra 4 città visitandole tutte:}
    \begin{itemize}
        \item $n=4$ (città)
        \item $P_4 = 4! = 24$ possibili percorsi
    \end{itemize}
\end{enumerate}

\subsubsection{Disposizioni Semplici}
\textbf{Formula:} $D_{n,k} = \frac{n!}{(n-k)!} = n \cdot (n-1) \cdot \dots \cdot (n-k+1)$

\textbf{Quando usarla:}
\begin{itemize}
    \item Quando NON possiamo riutilizzare gli elementi
    \item Quando l'\textbf{ordine} è importante
    \item Quando dobbiamo scegliere $k$ elementi da $n$
\end{itemize}

\textbf{Esempi:}
\begin{enumerate}
    \item \textbf{Podio in una gara con 10 atleti:}
    \begin{itemize}
        \item $n=10$ (atleti)
        \item $k=3$ (posizioni sul podio)
        \item L'ordine conta (1°, 2°, 3° posto)
        \item $D_{10,3} = \frac{10!}{7!} = 10 \cdot 9 \cdot 8 = 720$ possibili podi
    \end{itemize}

    \item \textbf{Scegliere presidente e tesoriere da 10 persone:}
    \begin{itemize}
        \item $n=10$ (persone)
        \item $k=2$ (ruoli)
        \item L'ordine conta perché i ruoli sono diversi (presidente $\neq$ tesoriere, quindi Alice presidente e Bob tesoriere è diverso da Bob presidente e Alice tesoriere)
        \item $D_{10,2} = 10 \cdot 9 = 90$ possibili assegnazioni
    \end{itemize}

    \item \textbf{PIN di 4 cifre diverse:}
    \begin{itemize}
        \item $n=10$ (cifre 0-9)
        \item $k=4$ (lunghezza PIN)
        \item Non posso riusare le cifre
        \item $D_{10,4} = 10 \cdot 9 \cdot 8 \cdot 7 = 5040$ possibili PIN
    \end{itemize}
\end{enumerate}

\subsubsection{Combinazioni Semplici}
\textbf{Formula:} $\binom{n}{k} = \frac{n!}{k!(n-k)!}$

\textbf{Quando usarla:}
\begin{itemize}
    \item Quando NON possiamo riutilizzare gli elementi
    \item Quando l'\textbf{ordine NON} è importante
    \item Quando dobbiamo scegliere $k$ elementi da $n$
\end{itemize}

\textbf{Esempi:}
\begin{enumerate}
    \item \textbf{Formare una squadra di 5 persone da un gruppo di 12:}
    \begin{itemize}
        \item $n=12$ (persone disponibili)
        \item $k=5$ (dimensione squadra)
        \item L'ordine non conta (è la stessa squadra)
        \item $\binom{12}{5} = \frac{12!}{5!(12-5)!} = 792$ possibili squadre
    \end{itemize}

    \item \textbf{Esempio:} Gruppo Roma/Firenze
    \begin{itemize}
        \item $n=10$ (studenti totali)
        \item $k=5$ (studenti per gruppo)
        \item L'ordine non conta
        \item $\binom{10}{5} = 252$ possibili gruppi
    \end{itemize}

    \item \textbf{Esempio:} Scegliere 2 lupi da 10 amici
    \begin{itemize}
        \item $n=10$ (amici)
        \item $k=2$ (lupi da scegliere)
        \item L'ordine non conta
        \item $\binom{10}{2} = 45$ possibili coppie di lupi
    \end{itemize}

    \item \textbf{Mano di 5 carte da un mazzo di 52:}
    \begin{itemize}
        \item $n=52$ (carte nel mazzo)
        \item $k=5$ (carte nella mano)
        \item L'ordine non conta
        \item $\binom{52}{5} = 2{,}598{,}960$ possibili mani
    \end{itemize}
\end{enumerate}

\begin{example}[Esercizio 2, 08/09/2023 - Studenti biondi a Roma]\label{ex:studenti-roma}
\textit{Problema:} Una classe di 10 studenti (4 biondi, 6 non biondi) è divisa in due gruppi di 5, uno per Roma e uno per Firenze. Qual è la probabilità che 2 studenti biondi vadano a Roma?

\textbf{Spiegazione Semplice:}
Immaginiamo di avere 10 studenti in classe:
\begin{itemize}
    \item 4 studenti biondi (chiamiamoli B1, B2, B3, B4)
    \item 6 studenti non biondi (chiamiamoli N1, N2, N3, N4, N5, N6)
\end{itemize}

\textbf{Cosa ci chiede il problema?}
Dobbiamo calcolare la probabilità che ESATTAMENTE 2 studenti biondi finiscano nel gruppo di Roma (che deve essere di 5 studenti in totale).

\textbf{Come si calcola la probabilità?}
Come sempre in probabilità, useremo la formula:
\[ \text{Probabilità} = \frac{\text{Casi favorevoli}}{\text{Casi possibili}} \]

\textit{Soluzione Passo Passo:}
\begin{enumerate}
    \item \textbf{Calcolare i casi possibili (denominatore):}
    \begin{itemize}
        \item Dobbiamo scegliere 5 studenti da un totale di 10 per mandarli a Roma
        \item L'ordine NON conta (non importa chi entra prima nel gruppo)
        \item Quindi usiamo le combinazioni: $\binom{10}{5}$
        \item $|\Omega| = \binom{10}{5} = \frac{10!}{5!5!} = \frac{10 \cdot 9 \cdot 8 \cdot 7 \cdot 6}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 252$
    \end{itemize}

    \item \textbf{Calcolare i casi favorevoli (numeratore):}
    Qui sta il punto più difficile! Per avere ESATTAMENTE 2 biondi a Roma, dobbiamo:
    \begin{itemize}
        \item Scegliere 2 studenti biondi tra i 4 disponibili
        \item E ANCHE scegliere 3 studenti non biondi tra i 6 disponibili
        \item (perché il gruppo di Roma deve essere di 5 persone in totale!)
    \end{itemize}

    Usiamo il metodo delle scelte successive per calcolare il numero di casi favorevoli. \textbf{Perché?}
    Facciamo un esempio pratico:
    \begin{itemize}
        \item Prima scegliamo 2 biondi: potremmo scegliere B1 e B2
        \item Per OGNI scelta dei biondi, dobbiamo scegliere 3 non biondi: potremmo scegliere N1, N2, N3
        \item Quindi un possibile gruppo sarebbe: \{B1, B2, N1, N2, N3\}
        \item Ma potevamo anche scegliere B1 e B3 come biondi, e poi N1, N2, N3 come non biondi
        \item O B1 e B3 come biondi, e N2, N3, N4 come non biondi
        \item E così via...
    \end{itemize}

    Per ogni modo di scegliere 2 biondi ($\binom{4}{2} = 6$ modi), dobbiamo considerare tutti i modi di scegliere 3 non biondi ($\binom{6}{3} = 20$ modi).
    Quindi moltiplichiamo:
    \[ |B_2| = \binom{4}{2} \cdot \binom{6}{3} = 6 \cdot 20 = 120 \text{ casi favorevoli} \]

    \item \textbf{Calcolare la probabilità finale:}
    \[ \Prob(B_2) = \frac{\text{Casi favorevoli}}{\text{Casi possibili}} = \frac{120}{252} = \frac{10}{21} \approx 0.48 \]
\end{enumerate}

\textbf{Verifica della logica:}
\begin{itemize}
    \item Se il risultato fosse 1, vorrebbe dire che SEMPRE vanno 2 biondi a Roma (impossibile!)
    \item Se fosse 0, vorrebbe dire che è IMPOSSIBILE che vadano 2 biondi a Roma (anche questo impossibile!)
    \item 0.48 significa che circa nel 48\% dei casi, quando dividiamo la classe in modo casuale, finiranno esattamente 2 biondi a Roma
\end{itemize}
\end{example}

\section{Probabilità Condizionata}
\label{sec:prob_cond}
Spesso siamo interessati alla probabilità di un evento $A$ sapendo che un altro evento $B$ si è già verificato. Questa è la probabilità condizionata.

\begin{definition}[Probabilità Condizionata]
Siano $A$ e $B$ due eventi con $\Prob(B) > 0$. La \textbf{probabilità condizionata} di $A$ dato $B$, indicata con $\Prob(A|B)$, è definita come:
\[ \Prob(A|B) = \frac{\Prob(A \cap B)}{\Prob(B)} \]
Intuizione: $B$ diventa il "nuovo" spazio campionario. Stiamo valutando la probabilità della parte di $A$ che si trova in $B$, normalizzata rispetto alla probabilità di $B$.
\end{definition}

\begin{corollary}[Regola della Catena]\label{cor:catena}
Siano $A$ e $B$ due eventi con $\Prob(B) > 0$. Vale:
\[ \Prob(A \cap B) = \Prob(A|B) \Prob(B) \]
Se inoltre $\Prob(A) > 0$, vale anche:
\[ \Prob(A \cap B) = \Prob(B|A) \Prob(A) \]
Per tre eventi $A$, $B$, $C$:
\[ \Prob(A \cap B \cap C) = \Prob(A) \Prob(B|A) \Prob(C|A \cap B) \]
con generalizzazioni analoghe per $n$ eventi.
\end{corollary}

\subsection{Diagrammi ad Albero e Probabilità Sequenziali}
\label{subsec:diagrammi_albero}

I diagrammi ad albero sono uno strumento grafico estremamente utile per rappresentare esperimenti aleatori che si svolgono in più fasi (o stadi) e per calcolare le probabilità degli eventi risultanti. Ogni percorso dalla radice dell'albero a una foglia rappresenta una possibile sequenza di esiti.

\paragraph{Come Costruire un Diagramma ad Albero}
\begin{enumerate}
    \item \textbf{Radice:} Il nodo iniziale rappresenta l'inizio dell'esperimento o lo stato iniziale.
    \item \textbf{Stadi e Rami:} Ogni stadio dell'esperimento è rappresentato da un livello di ramificazioni. Da ogni nodo, si dipartono tanti rami quanti sono i possibili esiti dello stadio successivo.
    \item \textbf{Etichette sui Rami:}
    \begin{itemize}
        \item I rami che partono dalla radice (primo stadio) sono etichettati con le probabilità dei rispettivi esiti iniziali.
        \item I rami che partono da nodi successivi (stadi successivi) sono etichettati con le \textbf{probabilità condizionate} dell'esito di quello stadio, dato che si è verificata la sequenza di esiti che ha portato a quel nodo.
    \end{itemize}
    \item \textbf{Foglie:} I nodi terminali dell'albero (le foglie) rappresentano gli esiti finali composti, ovvero una sequenza completa di eventi dall'inizio alla fine. Le etichette di questi nodi possono includere la probabilità congiunta del percorso.
\end{enumerate}

\paragraph{Come Usare un Diagramma ad Albero per Calcolare Probabilità}
\begin{itemize}
    \item \textbf{Probabilità di una Sequenza (Percorso):} Per calcolare la probabilità di una specifica sequenza di esiti (un percorso completo dalla radice a una foglia), si moltiplicano le probabilità associate a tutti i rami lungo quel percorso. Questo è un'applicazione diretta della Regola della Catena (Corollario~\ref{cor:catena}).
    \item \textbf{Probabilità di un Evento Composto:} Se un evento $E$ può verificarsi attraverso più sequenze (cioè, più percorsi portano a un risultato che soddisfa $E$), la probabilità di $E$ è la somma delle probabilità di tutti questi percorsi disgiunti. Questo è spesso una visualizzazione della Formula delle Probabilità Totali (Teorema~\ref{theorem:formula_probabilita_totali}).
\end{itemize}

\begin{example}[Scelta di una moneta e lancio]
Supponiamo di avere due monete:
\begin{itemize}
    \item Moneta A: bilanciata, $\Prob(Testa|A) = P(T|A) = 1/2$.
    \item Moneta B: truccata, $\Prob(Testa|B) = P(T|B) = 2/3$.
\end{itemize}
Scegliamo una moneta a caso ($\Prob(A) = 1/2, \Prob(B) = 1/2$) e la lanciamo una volta. Vogliamo calcolare la probabilità di ottenere Testa, $\Prob(T)$. Il diagramma ad albero per questo esperimento è mostrato in Figura~\ref{fig:albero_moneta_lancio}.

\begin{figure}[H] % H per "here if possible"
    \centering
    \includegraphics[width=0.9\textwidth]{images/albero_moneta_lancio.png}
    \caption{Diagramma ad albero per l'esperimento della scelta della moneta e lancio.}
    \label{fig:albero_moneta_lancio}
\end{figure}

Dalla Figura~\ref{fig:albero_moneta_lancio}, per ottenere $\Prob(T)$, sommiamo le probabilità dei percorsi che terminano in T. Le etichette dei nodi foglia mostrano le probabilità congiunte:
\begin{itemize}
    \item Percorso via Moneta A: $\Prob(A \cap T) = 1/4$.
    \item Percorso via Moneta B: $\Prob(B \cap T) = 1/3$.
\end{itemize}
Quindi:
\[ \Prob(T) = \Prob(A \cap T) + \Prob(B \cap T) = \frac{1}{4} + \frac{1}{3} = \frac{3+4}{12} = \frac{7}{12} \]
Questo è esattamente ciò che si otterrebbe applicando la Formula delle Probabilità Totali (Teorema~\ref{theorem:formula_probabilita_totali}), con la partizione data dalla scelta della moneta $\{A, B\}$:
\[ \Prob(T) = \Prob(T|A)\Prob(A) + \Prob(T|B)\Prob(B) = \left(\frac{1}{2} \cdot \frac{1}{2}\right) + \left(\frac{2}{3} \cdot \frac{1}{2}\right) = \frac{1}{4} + \frac{1}{3} = \frac{7}{12} \]
\end{example}

\begin{example}[Urna di Polya - Due Estrazioni]
Consideriamo l'urna dell'Esempio~\ref{cor:catena} con 4 palline Rosse (R) e 2 Nere (N). Si estraggono due palline con la regola di Polya (reimbussolamento con aggiunta di una pallina dello stesso colore estratto). Il diagramma ad albero corrispondente è illustrato in Figura~\ref{fig:albero_polya}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/albero_polya.png} % Usa \textwidth per larghezza massima
    \caption{Diagramma ad albero per due estrazioni dall'Urna di Polya.}
    \label{fig:albero_polya}
\end{figure}
Da questo albero (Figura~\ref{fig:albero_polya}), possiamo calcolare, ad esempio, la probabilità che la seconda pallina estratta sia Rossa ($\Prob(R_2)$). I percorsi che portano a $R_2$ sono $(R_1 \cap R_2)$ e $(N_1 \cap R_2)$. Le loro probabilità sono indicate sui nodi foglia:
\begin{itemize}
    \item $\Prob(R_1 \cap R_2) = 20/42$
    \item $\Prob(N_1 \cap R_2) = 8/42$
\end{itemize}
Sommando queste probabilità:
\[ \Prob(R_2) = \Prob(R_1 \cap R_2) + \Prob(N_1 \cap R_2) = \frac{20}{42} + \frac{8}{42} = \frac{28}{42} = \frac{2}{3} \]
Notare che $\Prob(R_1) = 4/6 = 2/3$. Per l'Urna di Polya, la probabilità di estrarre un certo colore a una data estrazione (non condizionata alle precedenti) rimane costante.
\end{example}

I diagrammi ad albero diventano particolarmente potenti quando si affrontano problemi che altrimenti richiederebbero una complessa applicazione della Formula delle Probabilità Totali (Teorema~\ref{theorem:formula_probabilita_totali}) o del Teorema di Bayes, in quanto rendono esplicite tutte le sequenze e le relative probabilità.

\begin{example}[Esercizio 1, 12/01/2024 - Urna di Polya]
\textit{Problema:} Urna con 6 palline (4 Rosse R, 2 Nere N). 3 estrazioni. Quando una pallina è estratta, viene reimbussolata con una nuova pallina dello stesso colore. Calcolare $\Prob(R_3)$, dove $R_3$ è "viene estratta una pallina rossa alla terza estrazione".
\textit{Soluzione (parte di essa, illustrando la regola della catena):}
Consideriamo una sequenza specifica, ad esempio $R_1 \cap N_2 \cap R_3$ (Rossa alla prima, Nera alla seconda, Rossa alla terza).
Usiamo la regola della catena: $\Prob(R_1 \cap N_2 \cap R_3) = \Prob(R_1) \Prob(N_2|R_1) \Prob(R_3|R_1 \cap N_2)$.
\begin{itemize}
    \item $\Prob(R_1)$: Inizialmente 4R, 2N (tot 6). $\Prob(R_1) = 4/6$.
    \item $\Prob(N_2|R_1)$: Se $R_1$ si è verificata, si è aggiunta una R. Urna ora: 5R, 2N (tot 7). $\Prob(N_2|R_1) = 2/7$.
    \item $\Prob(R_3|R_1 \cap N_2)$: Se $R_1$ e $N_2$ si sono verificate, si è aggiunta prima una R, poi una N. Urna ora: 5R, 3N (tot 8). $\Prob(R_3|R_1 \cap N_2) = 5/8$.
\end{itemize}
Quindi, $\Prob(R_1 \cap N_2 \cap R_3) = \frac{4}{6} \cdot \frac{2}{7} \cdot \frac{5}{8}$.
Per calcolare $\Prob(R_3)$ si devono considerare tutte le 8 possibili sequenze che portano a $R_3$ (RR$R_3$, RN$R_3$, NR$R_3$, NN$R_3$) e sommare le loro probabilità (lo vedremo meglio con la formula delle probabilità totali (Teorema~\ref{theorem:formula_probabilita_totali})).
\end{example}

\subsection{Indipendenza tra Eventi}
\begin{definition}[Indipendenza tra Eventi]
Due eventi $A$ e $B$ si dicono \textbf{indipendenti} se il verificarsi di uno non influenza la probabilità del verificarsi dell'altro. Formalmente:
\[ \Prob(A \cap B) = \Prob(A) \Prob(B) \]
Se $\Prob(B)>0$, l'indipendenza è equivalente a $\Prob(A|B) = \Prob(A)$.
Se $\Prob(A)>0$, l'indipendenza è equivalente a $\Prob(B|A) = \Prob(B)$.
\end{definition}

\begin{remark}
Non confondere eventi indipendenti con eventi incompatibili!
\begin{itemize}
    \item Se $A, B$ sono incompatibili ($A \cap B = \emptyset$) e $\Prob(A)>0, \Prob(B)>0$, allora $\Prob(A \cap B) = 0$. Ma $\Prob(A)\Prob(B) > 0$. Quindi $A$ e $B$ \textbf{non} sono indipendenti (anzi, sono fortemente dipendenti: se uno si verifica, l'altro non può).
    \item L'unica eccezione è se uno degli eventi ha probabilità zero.
\end{itemize}
\end{remark}

\begin{example}
Lancio di due dadi. Consideriamo gli eventi:
\begin{itemize}
    \item $A = \text{"il primo dado è 1"}$
    \item $B = \text{"la somma dei dadi è 7"}$
\end{itemize}
Lo spazio campionario $\Omega$ ha $6 \times 6 = 36$ esiti equiprobabili.

Gli eventi sono:
\begin{align*}
    A &= \{(1,1), (1,2), (1,3), (1,4), (1,5), (1,6)\} \\
    \Prob(A) &= \frac{6}{36} = \frac{1}{6} \\[1ex]
    B &= \{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\} \\
    \Prob(B) &= \frac{6}{36} = \frac{1}{6} \\[1ex]
    A \cap B &= \{(1,6)\} \\
    \Prob(A \cap B) &= \frac{1}{36}
\end{align*}

Verifichiamo l'indipendenza:
\[ \Prob(A)\Prob(B) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36} \]

Poiché $\Prob(A \cap B) = \Prob(A)\Prob(B)$, gli eventi $A$ e $B$ sono indipendenti.
\end{example}

\section{Formula delle Probabilità Totali e Teorema di Bayes}
Questi due strumenti sono potentissimi e molto usati negli esercizi.

\begin{definition}[Partizione dello Spazio Campionario]
Una famiglia di eventi $\{B_1, B_2, \dots, B_n\}$ costituisce una \textbf{partizione} di $\Omega$ se:
\begin{enumerate}
    \item $B_i \neq \emptyset$ per ogni $i$.
    \item $B_i \cap B_j = \emptyset$ per ogni $i \neq j$ (sono a due a due incompatibili).
    \item $\bigcup_{i=1}^n B_i = \Omega$ (la loro unione copre tutto lo spazio).
\end{enumerate}
\end{definition}

\begin{theorem}[Formula delle Probabilità Totali]\label{theorem:formula_probabilita_totali}
Sia $\{B_1, B_2, \dots, B_n\}$ una partizione di $\Omega$ tale che $\Prob(B_i) > 0$ per ogni $i$. Allora, per qualsiasi evento $A$:
\[ \Prob(A) = \sum_{i=1}^n \Prob(A \cap B_i) = \sum_{i=1}^n \Prob(A|B_i) \Prob(B_i) \]
\end{theorem}
\textit{Idea:} Per calcolare $\Prob(A)$, si "scompone" $A$ nelle sue parti che intersecano ciascun $B_i$, e si somma la probabilità di queste parti.

\begin{example}[Esercizio 1, 08/09/2023 - Gioco con due monete]
\textit{Problema (Parte 1):} Scommettitore sceglie a caso una di due monete: A (bilanciata, P(Testa)=1/2) o B (truccata, P(Testa)=2/3). Inizia con 1 euro, gioca max 5 volte. Vince 1 euro se Testa, perde 1 euro se Croce. Si ferma se perde tutto (0 euro) o vince 3 euro (ha 4 euro).
Calcolare $\Prob(I_2)$, dove $I_2 = \text{"il gioco si interrompe dopo il secondo lancio"}$.
\textit{Soluzione Passo Passo:}
\begin{enumerate}
    \item \textbf{Identificare la partizione:} L'evento iniziale che condiziona tutto è la scelta della moneta.
    Sia $D_A = \text{"viene scelta la moneta A"}$ e $D_B = \text{"viene scelta la moneta B"}$.
    Poiché la scelta è casuale, $\Prob(D_A) = 1/2$ e $\Prob(D_B) = 1/2$.
    $\{D_A, D_B\}$ è una partizione di $\Omega$ (relativo alla scelta della moneta).
    \item \textbf{Applicare la Formula delle Probabilità Totali a $I_2$:}
    $\Prob(I_2) = \Prob(I_2|D_A)\Prob(D_A) + \Prob(I_2|D_B)\Prob(D_B)$.
    \item \textbf{Analizzare $\Prob(I_2|D_A)$ e $\Prob(I_2|D_B)$:}
    Il giocatore inizia con 1 euro.
    Condizioni di stop: 0 euro o 4 euro.
    Perché il gioco si interrompa AL SECONDO lancio:
    \begin{itemize}
        \item NON deve interrompersi al primo lancio.
        \item DEVE interrompersi al secondo.
    \end{itemize}
    Analizziamo gli stati del capitale del giocatore ($S_0=1$):
    \begin{itemize}
        \item Lancio 1:
            \begin{itemize}
                \item Testa (T1): capitale $S_1=2$. Gioco continua.
                \item Croce (C1): capitale $S_1=0$. Gioco si ferma. Questo è $I_1$.
            \end{itemize}
    \end{itemize}
    Se il gioco arriva al secondo lancio, significa che al primo lancio è uscita Testa (capitale $S_1=2$).
    \begin{itemize}
        \item Lancio 2 (dato T1, quindi $S_1=2$):
            \begin{itemize}
                \item Testa (T2): capitale $S_2=3$. Gioco continua.
                \item Croce (C2): capitale $S_2=1$. Gioco continua.
            \end{itemize}
    \end{itemize}
    In nessuno dei due casi (Testa o Croce al secondo lancio) il giocatore ha 0 euro o 4 euro.
    Quindi, se il secondo lancio viene effettuato, il gioco NON si interrompe dopo il secondo lancio.
    L'unico modo per interrompersi \textbf{dopo} il secondo lancio sarebbe se al primo si fosse già interrotto, il che è una contraddizione.
    La soluzione fornita nell'esame afferma: "Si noti che, a prescindere dalla moneta utilizzata, se il secondo lancio viene effettuato, allora al primo lancio c'è stata una vittoria. In questo caso però, il giocatore dispone di 2 euro prima del secondo lancio, e perciò, se anche perdesse al secondo lancio, la sequenza non terminerebbe poiché avrebbe ancora un euro da giocare. Quindi $I_2 = \emptyset \Rightarrow \Prob(I_2) = 0$."
    Questo significa che $\Prob(I_2|D_A) = 0$ e $\Prob(I_2|D_B) = 0$.
    \item \textbf{Calcolare $\Prob(I_2)$:}
    $\Prob(I_2) = 0 \cdot (1/2) + 0 \cdot (1/2) = 0$.
\end{enumerate}
Questo esercizio specifico per $I_2$ era un po' un "trabocchetto" o un test di comprensione delle regole del gioco. Gli altri punti richiedono calcoli più standard.
\end{example}

\begin{example}[Esercizio 1, Punto 3, 08/09/2023]\label{example:esercizio_1_punto_3}
\textit{Problema:} Calcolare $\Prob(P|D_B)$, dove $P = $"il gioco termina con lo scommettitore che non perde tutti i soldi".

\textit{Soluzione Passo Passo:}
L'evento $P$ è "il gioco termina con lo scommettitore che non perde tutti i soldi".
È più facile calcolare $P^c = \text{"il giocatore perde tutti i soldi"}$ (cioè il suo capitale va a 0), e poi usare $\Prob(P|D_X) = 1 - \Prob(P^c|D_X)$.
Il giocatore inizia con 1 euro ($S_0=1$) e si ferma se $S_k=0$ (rovina) o $S_k=4$ (vittoria), oppure dopo 5 lanci.

\paragraph{Calcolo di $\Prob(P^c|D_B)$ (Moneta B: $p_B = \Prob(Testa) = 2/3$, $q_B = \Prob(Croce) = 1/3$)}
Identifichiamo le sequenze di lanci che portano alla rovina ($S_k=0$) quando si usa la moneta B, senza che prima si sia raggiunta la vittoria ($S_k=4$) e entro al massimo 5 lanci.
Il capitale iniziale è $S_0=1$.

\begin{itemize}
    \item \textbf{Rovina al 1° lancio:}
    Esce Croce (C1). Capitale $S_1 = 1-1 = 0$.
    Probabilità: $\Prob(C_1|D_B) = q_B = 1/3$.
    Sequenza: C.

    \item \textbf{Rovina al 3° lancio (non prima):}
    Per arrivare al 3° lancio senza rovina né vittoria immediata, la sequenza deve essere T1 C2.
    $S_0=1 \xrightarrow{T_1} S_1=2 \xrightarrow{C_2} S_2=1$. Ora, se esce C3, si va in rovina.
    Sequenza: T1 C2 C3. Capitale $S_3=0$.
    Probabilità: $\Prob(T_1 \cap C_2 \cap C_3 | D_B) = p_B \cdot q_B \cdot q_B = (2/3)(1/3)(1/3) = 2/27$.

    \item \textbf{Rovina al 5° lancio (non prima):}
    Ci sono due percorsi principali per arrivare al 5° lancio e andare in rovina, partendo da $S_0=1$ e senza aver vinto o perso prima:
    \begin{enumerate}
        \item $S_0=1 \xrightarrow{T_1} S_1=2 \xrightarrow{C_2} S_2=1 \xrightarrow{T_3} S_3=2 \xrightarrow{C_4} S_4=1$. Ora, se esce C5, si va in rovina.
        Sequenza: T1 C2 T3 C4 C5. Capitale $S_5=0$.
        Probabilità: $p_B \cdot q_B \cdot p_B \cdot q_B \cdot q_B = p_B^2 q_B^3 = (2/3)^2 (1/3)^3 = (4/9)(1/27) = 4/243$.

        \item $S_0=1 \xrightarrow{T_1} S_1=2 \xrightarrow{T_2} S_2=3 \xrightarrow{C_3} S_3=2 \xrightarrow{C_4} S_4=1$. Ora, se esce C5, si va in rovina.
        Sequenza: T1 T2 C3 C4 C5. Capitale $S_5=0$.
        Probabilità: $p_B \cdot p_B \cdot q_B \cdot q_B \cdot q_B = p_B^2 q_B^3 = (2/3)^2 (1/3)^3 = 4/243$.
    \end{enumerate}
    Nota: Se una sequenza porta a $S_k=4$ (vittoria), come TTT ($1 \to 2 \to 3 \to 4$), il gioco si ferma e non contribuisce alla rovina. Ad esempio, la sequenza TTT C C non è una sequenza di rovina perché il gioco si ferma a TTT con 4 euro.
\end{itemize}
Le sequenze di rovina identificate sono mutuamente esclusive. Quindi, la probabilità totale di rovina con la moneta B è la somma delle loro probabilità:
\[ \Prob(P^c|D_B) = \frac{1}{3} + \frac{2}{27} + \frac{4}{243} + \frac{4}{243} \]
\[ \Prob(P^c|D_B) = \frac{81}{243} + \frac{18}{243} + \frac{4}{243} + \frac{4}{243} = \frac{81+18+4+4}{243} = \frac{107}{243} \]
Questa è la probabilità che lo scommettitore perda tutti i soldi usando la moneta B.
Di conseguenza, la probabilità richiesta dall'Esercizio 1, Punto 3, è:
\[ \Prob(P|D_B) = 1 - \Prob(P^c|D_B) = 1 - \frac{107}{243} = \frac{243 - 107}{243} = \frac{136}{243} \]

\paragraph{Calcolo di $\Prob(P^c|D_A)$ (Moneta A: $p_A = \Prob(Testa) = 1/2$, $q_A = \Prob(Croce) = 1/2$)}
Seguendo la stessa logica, con $p_A=q_A=1/2$:
\begin{itemize}
    \item Rovina al 1° lancio (C1): $\Prob(C_1|D_A) = 1/2$.
    \item Rovina al 3° lancio (T1 C2 C3): $\Prob(T_1 C_2 C_3|D_A) = (1/2)^3 = 1/8$.
    \item Rovina al 5° lancio (T1 C2 T3 C4 C5): $\Prob(T_1 C_2 T_3 C_4 C_5|D_A) = (1/2)^5 = 1/32$.
    \item Rovina al 5° lancio (T1 T2 C3 C4 C5): $\Prob(T_1 T_2 C_3 C_4 C_5|D_A) = (1/2)^5 = 1/32$.
\end{itemize}
\[ \Prob(P^c|D_A) = \frac{1}{2} + \frac{1}{8} + \frac{1}{32} + \frac{1}{32} = \frac{16}{32} + \frac{4}{32} + \frac{1}{32} + \frac{1}{32} = \frac{16+4+1+1}{32} = \frac{22}{32} = \frac{11}{16} \]
Quindi:
\[ \Prob(P|D_A) = 1 - \Prob(P^c|D_A) = 1 - \frac{11}{16} = \frac{5}{16} \]
Questi sono i valori $\Prob(P|D_A)=5/16$ e $\Prob(P|D_B)=136/243$ che vengono usati nella soluzione dell'esame per il punto 4 (esempio~\ref{example:esercizio_1_punto_4}).
\end{example}

\begin{theorem}[Teorema di Bayes]
Sia $\{B_1, B_2, \dots, B_n\}$ una partizione di $\Omega$ con $\Prob(B_i) > 0$ per ogni $i$. Sia $A$ un evento con $\Prob(A) > 0$. Allora, per ogni $k=1, \dots, n$:
\[ \Prob(B_k|A) = \frac{\Prob(A|B_k) \Prob(B_k)}{\Prob(A)} = \frac{\Prob(A|B_k) \Prob(B_k)}{\sum_{i=1}^n \Prob(A|B_i) \Prob(B_i)} \]
\end{theorem}
\textit{Idea:} Il teorema di Bayes ci permette di "invertire" la probabilità condizionata. Se conosciamo $\Prob(A|B_k)$ (la probabilità dell'effetto data la causa), possiamo calcolare $\Prob(B_k|A)$ (la probabilità della causa dato l'effetto).
$\Prob(B_k)$ è detta probabilità \textit{a priori} di $B_k$.
$\Prob(B_k|A)$ è detta probabilità \textit{a posteriori} di $B_k$ (dopo aver osservato $A$).

\begin{example}[Esercizio 1, Punto 4, 08/09/2023]\label{example:esercizio_1_punto_4}
\textit{Problema:} Determinare $\Prob(D_A|P)$, dove $P = $"il gioco termina con lo scommettitore che non perde tutti i soldi".

\noindent Ricordiamo $D_A = \text{"viene scelta la moneta A"}$.
\textit{Soluzione Passo Passo:}
\begin{enumerate}
    \item \textbf{Applicare il Teorema di Bayes:}
    \[ \Prob(D_A|P) = \frac{\Prob(P|D_A)\Prob(D_A)}{\Prob(P)} \]
    \item \textbf{Scomporre $\Prob(P)$ usando la Formula delle Probabilità Totali:}
    La partizione è $\{D_A, D_B\}$.
    \[ \Prob(P) = \Prob(P|D_A)\Prob(D_A) + \Prob(P|D_B)\Prob(D_B) \]
    Quindi:
    \[ \Prob(D_A|P) = \frac{\Prob(P|D_A)\Prob(D_A)}{\Prob(P|D_A)\Prob(D_A) + \Prob(P|D_B)\Prob(D_B)} \]
    \item \textbf{Utilizzare i valori calcolati precedentemente:}
    Sappiamo $\Prob(D_A) = 1/2$ e $\Prob(D_B) = 1/2$.
    La soluzione dell'esame al punto 3 (esempio~\ref{example:esercizio_1_punto_3}) calcola $\Prob(P|D_B) = 136/243$ e $\Prob(P|D_A) = 5/16$.
    \item \textbf{Sostituire i valori:}
    \[ \Prob(D_A|P) = \frac{(5/16) \cdot (1/2)}{(5/16) \cdot (1/2) + (136/243) \cdot (1/2)} \]
    Si può semplificare il $1/2$:
    \[ \Prob(D_A|P) = \frac{5/16}{5/16 + 136/243} = \frac{5/16}{(5 \cdot 243 + 136 \cdot 16)/(16 \cdot 243)} = \frac{5/16}{(1215 + 2176)/3888} = \frac{5/16}{3391/3888} \]
    \[ = \frac{5}{16} \cdot \frac{3888}{3391} = \frac{5 \cdot 243}{3391} = \frac{1215}{3391} \]
\end{enumerate}
\textbf{Come si calcolano $\Prob(P|D_A)$ e $\Prob(P|D_B)$?}
L'evento $P$ è "il gioco termina con lo scommettitore che non perde tutti i soldi". Questo significa che o il giocatore raggiunge i 4 euro, oppure arriva al 5° lancio senza essere andato in rovina e senza aver raggiunto i 4 euro, e termina con un capitale $>0$.
Alternativamente, è più facile calcolare $P^c = \text{"il giocatore perde tutti i soldi"}$, e poi fare $\Prob(P|D_X) = 1 - \Prob(P^c|D_X)$.
Per calcolare $\Prob(P^c|D_X)$ (probabilità di rovina dato che si usa la moneta X), si deve tracciare un albero delle possibili sequenze di gioco e dei capitali, fermandosi quando il capitale è 0 (rovina) o 4 (vittoria) o dopo 5 lanci.
Ad esempio, per $\Prob(P^c|D_A)$ (moneta bilanciata, $p=1/2$ per Testa, $q=1/2$ per Croce):
Capitale iniziale $S_0=1$.
Sequenze di rovina:
\begin{itemize}
    \item C (costo 1/2): $S_1=0$. Rovina. Prob = 1/2.
    \item TC C (costo 1/2, 1/2, 1/2): $S_0=1 \xrightarrow{T} S_1=2 \xrightarrow{C} S_2=1 \xrightarrow{C} S_3=0$. Rovina. Prob = $(1/2)^3 = 1/8$.
    \item TC TC C (costo $(1/2)^5$): $S_0=1 \xrightarrow{T} 2 \xrightarrow{C} 1 \xrightarrow{T} 2 \xrightarrow{C} 1 \xrightarrow{C} 0$. Rovina. Prob = $(1/2)^5 = 1/32$.
    \item TTT C C (costo $(1/2)^5$): $S_0=1 \xrightarrow{T} 2 \xrightarrow{T} 3 \xrightarrow{T} 4$ (STOP VITTORIA). Questa non è rovina.
    \item ... e altre.
\end{itemize}
La soluzione dell'esame usa un approccio che somma le probabilità dei percorsi che portano alla rovina, condizionati alla scelta della moneta.
Per $\Prob(P|D_A) = 1 - \Prob(P^c|D_A)$:
$\Prob(P^c|D_A)$ (rovina con moneta A, $p_A=1/2$):
\begin{itemize}
    \item C1: $1/2$
    \item T1 C2 C3: $(1/2)^3 = 1/8$
    \item T1 C2 T3 C4 C5: $(1/2)^5 = 1/32$
    \item T1 T2 C3 C4 C5: $(1/2)^5 = 1/32$
\end{itemize}
Somma delle probabilità di rovina: $1/2 + 1/8 + 1/32 + 1/32 = 16/32 + 4/32 + 1/32 + 1/32 = 22/32 = 11/16$.
Quindi $\Prob(P|D_A) = 1 - 11/16 = 5/16$. Questo è corretto come nella soluzione.

Per $\Prob(P^c|D_B)$ (rovina con moneta B, $p_B=2/3$ per Testa, $q_B=1/3$ per Croce):
\begin{itemize}
    \item C1: $q_B = 1/3$
    \item T1 C2 C3: $p_B q_B^2 = (2/3)(1/3)^2 = 2/27$
    \item T1 C2 T3 C4 C5: $p_B q_B p_B q_B^2 = p_B^2 q_B^3 = (2/3)^2 (1/3)^3 = 4/27 \cdot 1/27 = 4/243$ (La soluzione dell'esame ha un errore qui, usa $(1/3)^5$ che non ha senso, dovrebbe essere $p_B^2 q_B^3$. No, la soluzione dell'esame è P(C1|DB) + P(T1|DB)P(C2|DB/\text{T1})P(C3|DB/\text{T1}/\text{C2}) + ... che è corretto. Il mio errore era nell'interpretare la formula della soluzione.
    Rivediamo la soluzione dell'esame per $P(P^c|D_B)$:
    \begin{itemize}
        \item $P(C_1|D_B) = 1/3$ (Capitale 0. Rovina)
        \item $P(T_1 \cap C_2 \cap C_3 | D_B) = (2/3)(1/3)(1/3) = 2/27$ (Capitale $1 \to 2 \to 1 \to 0$. Rovina)
        \item $P(T_1 \cap C_2 \cap T_3 \cap C_4 \cap C_5 | D_B) = (2/3)(1/3)(2/3)(1/3)(1/3) = 4/243$ (Capitale $1 \to 2 \to 1 \to 2 \to 1 \to 0$. Rovina)
        \item $P(T_1 \cap T_2 \cap C_3 \cap C_4 \cap C_5 | D_B) = (2/3)(2/3)(1/3)(1/3)(1/3) = 4/243$ (Capitale $1 \to 2 \to 3 \to 2 \to 1 \to 0$. Rovina)
    \end{itemize}
    Sommando: $P(P^c|D_B) = 1/3 + 2/27 + 4/243 + 4/243 = (81+18+4+4)/243 = 107/243$.
    Quindi $\Prob(P|D_B) = 1 - 107/243 = (243-107)/243 = 136/243$. Questo è corretto.
\end{itemize}
La chiave è tracciare attentamente l'albero delle decisioni e dei capitali, fermandosi alle condizioni di stop (0 euro, 4 euro, o 5 lanci).
\end{example}

Questo conclude il primo capitolo sui fondamenti. Dovrebbe darti una base solida. Il prossimo passo sarà introdurre le variabili aleatorie.

\end{document}
