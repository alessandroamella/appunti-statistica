\input{preambolo_comune}

% --- Titolo ---
\title{Variabili Aleatorie Congiunte}
\author{Basato sulle prove d'esame}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\label{cap:va_congiunte}
Spesso siamo interessati a studiare due o più variabili aleatorie definite sullo stesso esperimento.

\section{Caso Discreto}
\begin{definition}[Funzione di Massa di Probabilità Congiunta]
Date due v.a. discrete $X$ e $Y$, la loro \textbf{funzione di massa di probabilità congiunta} è:
\[ p_{X,Y}(x,y) = \Prob(X=x, Y=y) \]
Proprietà:
\begin{enumerate}
    \item $p_{X,Y}(x,y) \ge 0$.
    \item $\sum_x \sum_y p_{X,Y}(x,y) = 1$.
\end{enumerate}
\end{definition}

\begin{definition}[Distribuzioni Marginali]
Dalla PMF congiunta, possiamo ottenere le PMF delle singole variabili (marginali):
\[ p_X(x) = \Prob(X=x) = \sum_y p_{X,Y}(x,y) \]
\[ p_Y(y) = \Prob(Y=y) = \sum_x p_{X,Y}(x,y) \]
\end{definition}

\begin{definition}[Distribuzioni Condizionate]
La PMF condizionata di $Y$ dato $X=x$ (con $p_X(x)>0$) è:
\[ p_{Y|X}(y|x) = \Prob(Y=y|X=x) = \frac{\Prob(X=x, Y=y)}{\Prob(X=x)} = \frac{p_{X,Y}(x,y)}{p_X(x)} \]
Similmente per $p_{X|Y}(x|y)$.
\end{definition}

\section{Caso Continuo}
\begin{definition}[Funzione di Densità di Probabilità Congiunta]
Date due v.a. continue $X$ e $Y$, la loro \textbf{funzione di densità di probabilità congiunta} $f_{X,Y}(x,y)$ è tale che:
\begin{enumerate}
    \item $f_{X,Y}(x,y) \ge 0$.
    \item $\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f_{X,Y}(x,y) \dd x \dd y = 1$.
    \item $\Prob((X,Y) \in A) = \iint_A f_{X,Y}(x,y) \dd x \dd y$ per $A \subseteq \R^2$.
\end{enumerate}
\end{definition}

\begin{definition}[Distribuzioni Marginali]
\[ f_X(x) = \int_{-\infty}^{+\infty} f_{X,Y}(x,y) \dd y \]
\[ f_Y(y) = \int_{-\infty}^{+\infty} f_{X,Y}(x,y) \dd x \]
\end{definition}

\begin{definition}[Distribuzioni Condizionate]
La PDF condizionata di $Y$ dato $X=x$ (con $f_X(x)>0$) è:
\[ f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)} \]
Similmente per $f_{X|Y}(x|y)$.
\end{definition}

\section{Indipendenza tra Variabili Aleatorie}
\begin{definition}[Indipendenza]
Due v.a. $X$ e $Y$ sono \textbf{indipendenti} se per ogni $x,y$:
\begin{itemize}
    \item Caso discreto: $p_{X,Y}(x,y) = p_X(x) p_Y(y)$.
    \item Caso continuo: $f_{X,Y}(x,y) = f_X(x) f_Y(y)$.
\end{itemize}
Equivalentemente, $F_{X,Y}(x,y) = F_X(x) F_Y(y)$.
Se $X,Y$ sono indipendenti, allora $\E[XY] = \E[X]\E[Y]$.
Se $X,Y$ sono indipendenti, allora $\E[g(X)h(Y)] = \E[g(X)]\E[h(Y)]$.
\end{definition}

\begin{example}[Esercizio 3, Punto 1, 12/01/2024 - Completare tabella]
\textit{Problema:} Completare la tabella di probabilità congiunta in modo che $X, Y$ siano indipendenti.
\begin{center}
\begin{tabular}{c|ccc|c}
$Y \setminus X$ & -2 & 0 & 3 & $p_X(x)$ \\ \hline
-1 & $p(-1,-2)$ & 0.2 & $p(-1,3)$ & $p_X(-1)$ \\
3 & 0.1 & $p(3,0)$ & $p(3,3)$ & $p_X(3)$ \\ \hline
$p_Y(y)$ & $p_Y(-2)$ & 0.4 & $p_Y(3)$ & 1
\end{tabular}
\end{center}
Valori noti: $p(-1,0)=0.2$, $p(3,-2)=0.1$, $p_Y(0)=0.4$.
\textit{Soluzione Passo Passo:}
\begin{enumerate}
    \item \textbf{Usare la complementarità per $p_{X,Y}(3,0)$:}
    La colonna di $Y=0$ deve sommare a $p_Y(0)=0.4$.
    $p(-1,0) + p(3,0) = p_Y(0) \Rightarrow 0.2 + p(3,0) = 0.4 \Rightarrow p(3,0) = 0.2$.
    \item \textbf{Usare l'indipendenza $p(x,y) = p_X(x)p_Y(y)$:}
    Da $p(3,0) = 0.2$: $p(3,0) = p_X(3) \cdot p_Y(0) \Rightarrow 0.2 = p_X(3) \cdot 0.4 \Rightarrow p_X(3) = 0.2/0.4 = 0.5$.
    \item \textbf{Calcolare $p_X(-1)$:}
    Le probabilità marginali $p_X(x)$ devono sommare a 1.
    $p_X(-1) + p_X(3) = 1 \Rightarrow p_X(-1) + 0.5 = 1 \Rightarrow p_X(-1) = 0.5$.
    \item \textbf{Usare l'indipendenza per $p(-1,0)$:}
    $p(-1,0) = p_X(-1) \cdot p_Y(0) \Rightarrow 0.2 = 0.5 \cdot 0.4 \Rightarrow 0.2 = 0.2$. (Consistente!)
    \item \textbf{Usare l'indipendenza per $p(3,-2)$:}
    $p(3,-2) = p_X(3) \cdot p_Y(-2) \Rightarrow 0.1 = 0.5 \cdot p_Y(-2) \Rightarrow p_Y(-2) = 0.1/0.5 = 0.2$.
    \item \textbf{Calcolare $p_Y(3)$:}
    Le probabilità marginali $p_Y(y)$ devono sommare a 1.
    $p_Y(-2) + p_Y(0) + p_Y(3) = 1 \Rightarrow 0.2 + 0.4 + p_Y(3) = 1 \Rightarrow 0.6 + p_Y(3) = 1 \Rightarrow p_Y(3) = 0.4$.
    \item \textbf{Completare le celle rimanenti usando l'indipendenza:}
    $p(-1,-2) = p_X(-1)p_Y(-2) = 0.5 \cdot 0.2 = 0.1$.
    $p(-1,3) = p_X(-1)p_Y(3) = 0.5 \cdot 0.4 = 0.2$.
    $p(3,3) = p_X(3)p_Y(3) = 0.5 \cdot 0.4 = 0.2$.
\end{enumerate}
Tabella completata:
\begin{center}
\begin{tabular}{c|ccc|c}
$Y \setminus X$ & -2 & 0 & 3 & $p_X(x)$ \\ \hline
-1 & \textbf{0.1} & 0.2 & \textbf{0.2} & \textbf{0.5} \\
3 & 0.1 & \textbf{0.2} & \textbf{0.2} & \textbf{0.5} \\ \hline
$p_Y(y)$ & \textbf{0.2} & 0.4 & \textbf{0.4} & 1
\end{tabular}
\end{center}
\end{example}

\section{Covarianza e Correlazione}
\begin{definition}[Covarianza]
La \textbf{covarianza} tra due v.a. $X$ e $Y$ misura la loro tendenza a variare insieme:
\[ \Cov(X,Y) = \E[(X-\E[X])(Y-\E[Y])] \]
Formula computazionale:
\[ \Cov(X,Y) = \E[XY] - \E[X]\E[Y] \]
dove $\E[XY] = \sum_x \sum_y xy \cdot p_{X,Y}(x,y)$ (discreto) o $\iint xy f_{X,Y}(x,y) \dd x \dd y$ (continuo).
Proprietà:
\begin{itemize}
    \item $\Cov(X,X) = \Var(X)$.
    \item $\Cov(X,Y) = \Cov(Y,X)$.
    \item $\Cov(aX+b, cY+d) = ac \Cov(X,Y)$.
    \item $\Var(X+Y) = \Var(X) + \Var(Y) + 2\Cov(X,Y)$.
    \item Se $X, Y$ sono indipendenti, allora $\Cov(X,Y) = 0$. \textbf{Attenzione:} $\Cov(X,Y)=0$ non implica indipendenza, a meno che $X,Y$ non siano Normali.
\end{itemize}
\end{definition}

\begin{definition}[Coefficiente di Correlazione]
Il \textbf{coefficiente di correlazione lineare} $\rho_{X,Y}$ normalizza la covarianza:
\[ \rho_{X,Y} = \frac{\Cov(X,Y)}{\sqrt{\Var(X)\Var(Y)}} = \frac{\Cov(X,Y)}{\sigma_X \sigma_Y} \]
Proprietà:
\begin{itemize}
    \item $-1 \le \rho_{X,Y} \le 1$.
    \item Se $\rho_{X,Y} = 1$, c'è una relazione lineare positiva perfetta ($Y=aX+b$ con $a>0$).
    \item Se $\rho_{X,Y} = -1$, c'è una relazione lineare negativa perfetta ($Y=aX+b$ con $a<0$).
    \item Se $\rho_{X,Y} = 0$, non c'è correlazione lineare (ma potrebbe esserci una dipendenza non lineare).
    \item Se $X,Y$ sono indipendenti, $\rho_{X,Y}=0$.
\end{itemize}
\end{definition}
\begin{example}[Esercizio 3, Punto 4, 08/09/2023]
Affinché $\rho_{X,Y}=1$ deve valere $Y = f(X) = aX+b$ con $a>0$.
Date le condizioni $\Var(Y) = \E[Y]=2$ e $\E[X]=2, \Var(X)=2$.
Usiamo le proprietà:
$\E[Y] = \E[aX+b] = a\E[X]+b = 2a+b$.
$\Var(Y) = \Var(aX+b) = a^2\Var(X) = a^2(2)$.
Quindi:
$2a+b = 2$
$2a^2 = 2 \Rightarrow a^2 = 1$. Poiché $a>0$, si ha $a=1$.
Sostituendo $a=1$ nella prima: $2(1)+b=2 \Rightarrow b=0$.
Quindi $f(x) = x$.
\end{example}

\end{document}
